{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from joblib import dump, load\n",
    "import argparse\n",
    "from codecarbon import EmissionsTracker\n",
    "import subprocess\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def emissions_tracker(tracker_outpath):\n",
    "    \"\"\"\n",
    "    The function initializes an EmissionsTracker object to track carbon emissions associated\n",
    "    with code execution. The results of this can be found in portfolio 5.\n",
    "    \"\"\"\n",
    "    tracker = EmissionsTracker(project_name = \"portfolio 2\",\n",
    "                                experiment_id = \"portfolio_2\",\n",
    "                                output_dir = tracker_outpath,\n",
    "                                output_file = \"emissions_portfolio2.csv\")\n",
    "    return tracker\n",
    "\n",
    "\n",
    "def parser():\n",
    "    \"\"\"\n",
    "    The user can specify whether to perform GridSearch and/or permutation testing when executing\n",
    "    the script. The function will then parse command-line arguments and make them lower case.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--GridSearch\",\n",
    "                        \"-gs\",\n",
    "                        required = True,\n",
    "                        help = \"Perform GridSearch (yes or no)\")\n",
    "    parser.add_argument(\"--PermutationTest\",\n",
    "                        \"-pt\",\n",
    "                        required = True,\n",
    "                        help = \"Perform permutation test (yes or no)\")    \n",
    "    args = parser.parse_args()\n",
    "    args.GridSearch = args.GridSearch.lower()\n",
    "    args.PermutationTest = args.PermutationTest.lower()\n",
    "    return args\n",
    "\n",
    "\n",
    "def load_vectorised_data():\n",
    "    \"\"\"\n",
    "    The Python subprocess module is a tool that allows you to run other programs or commands\n",
    "    from your Python code. It can be used to open new programs, send them data and get results back.\n",
    "    \"\"\"\n",
    "    if os.path.isfile('models/vectorized_data.pkl'):\n",
    "        vectorized_data = joblib.load('models/vectorized_data.pkl')\n",
    "        X_train_features, y_train, X_test_features, y_test = vectorized_data\n",
    "    else:\n",
    "        subprocess.run(['python', 'vectorizer.py']) # capture_output=True, text=True)\n",
    "        X_train_features, y_train, X_test_features, y_test = vectorized_data\n",
    "\n",
    "    return X_train_features, y_train, X_test_features, y_test\n",
    "\n",
    "\n",
    "def define_classifier():\n",
    "    \"\"\"\n",
    "    Function that defines logistic regression classifier with default parameters.\n",
    "    \"\"\"\n",
    "    classifier = LogisticRegression(tol = 0.0001,\n",
    "                                    max_iter = 100,\n",
    "                                    solver = 'lbfgs',\n",
    "                                    penalty = 'l2',\n",
    "                                    random_state = 123,\n",
    "                                    verbose = True)\n",
    "    return classifier\n",
    "\n",
    "\n",
    "def grid_search(classifier, X_train, y_train):\n",
    "    tol = [0.01, 0.001, 0.0001, 0.00001]\n",
    "    max_iter = [100, 200, 300]\n",
    "\n",
    "    param_grid = (\n",
    "        [{'tol': tol, 'max_iter': max_iter, 'solver': ('saga', 'liblinear'), 'penalty': ('l1')},\n",
    "        {'tol': tol, 'max_iter': max_iter, 'solver': ('saga', 'liblinear', 'lbfgs', 'newton-cg'), 'penalty': ('l2')}]\n",
    "        )\n",
    "\n",
    "    grid_search = GridSearchCV(estimator = classifier, param_grid = param_grid, cv = 5, n_jobs = -1)\n",
    "    grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(f'Best Accuracy for {grid_result.best_score_} using the parameters {grid_result.best_params_}')\n",
    "\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(f' mean={mean:.4}, std={stdev:.4} using {param}')\n",
    "\n",
    "    best_estimator = grid_result.best_estimator_\n",
    "    return best_estimator\n",
    "\n",
    "\n",
    "def fit_classifier(classifier, X_train, y_train):\n",
    "    \"\"\"\n",
    "    The function fits the LR classifier to the training data.\n",
    "    - fits either the vectorised data to default LR parameters or parameters obtained through GridSearch\n",
    "    \"\"\"\n",
    "    classifier = classifier.fit(X_train, y_train)\n",
    "    return classifier\n",
    "\n",
    "\n",
    "def evaluate_classifier(classifier, X_train_features, y_train, X_test_features, y_test, outpath):\n",
    "    \"\"\"\n",
    "    The function evaluates the trained classifier on new, unseen data. This includes plotting a confusion\n",
    "    matrix and calculating a classification report, which will be saved to a specified outpath.\n",
    "    \"\"\"\n",
    "    y_pred = classifier.predict(X_test_features)\n",
    "    metrics.ConfusionMatrixDisplay.from_estimator(classifier, \n",
    "                                                X_test_features, y_train,\n",
    "                                                cmap = plt.cm.Blues,\n",
    "                                                labels = [\"FAKE\", \"REAL\"])\n",
    "\n",
    "    classifier_metrics = metrics.classification_report(y_test, y_pred, target_names = [\"FAKE\", \"REAL\"])\n",
    "    print(classifier_metrics)\n",
    "\n",
    "    with open(outpath, 'w') as file:\n",
    "        file.write(classifier_metrics)\n",
    "    return print(\"The classification report has been saved to the out folder\")\n",
    "\n",
    "\n",
    "def permutation_test(classifier, X_train_features, y_train, outpath):\n",
    "    \"\"\"\n",
    "    Performs permutation test on the LR classifier to assess statistical significance of classifier's\n",
    "    performance. The permutation test will be plotted and saved to a specified outpath.\n",
    "    \"\"\"\n",
    "    score, permutation_scores, pvalue = permutation_test_score(classifier, X_train_features, y_train,\n",
    "                                                                cv = 5, n_permutations = 100,\n",
    "                                                                n_jobs = -1, random_state = 123,\n",
    "                                                                verbose = True, coring = None)\n",
    "    n_classes = 2\n",
    "\n",
    "    plt.figure(figsize = (8, 6))\n",
    "    plt.hist(permutation_scores, 20, label = 'Permutation scores', edgecolor = 'black')\n",
    "    ylim = plt.ylim()\n",
    "    plt.plot(2 * [score], ylim, '--g', linewidth = 3,label = 'Classification Score'' (pvalue %s)' % pvalue)\n",
    "    plt.plot(2 * [1. / n_classes], ylim, '--k', linewidth = 3, label = 'Chance level')\n",
    "    plt.title(\"Permutation test logistic regression classifier\")\n",
    "    plt.ylim(ylim)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Score')\n",
    "    plt.savefig(outpath)\n",
    "    plt.show()\n",
    "    return print(\"The permutation test has been saved to the out folder\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    args = parser()\n",
    "\n",
    "    X_train_features, y_train, X_test_features, y_test = load_vectorised_data()\n",
    "\n",
    "    classifier = define_classifier()\n",
    "\n",
    "    if args.GridSearch == 'yes':\n",
    "        classifier = grid_search(classifier, X_train_features, y_train)\n",
    "\n",
    "    fit_classifier(classifier, X_train_features, y_train)\n",
    "\n",
    "    evaluate_classifier(classifier, X_train_features, y_train, X_test_features, y_test,\n",
    "                         \"out/LR_classification_report.txt\")\n",
    "\n",
    "    if args.PermutationTest == 'yes':\n",
    "        permutation_test(classifier, X_test, y_test, \"out/LR_permutation.png\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
