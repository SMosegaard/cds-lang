{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio 1 - Extracting linguistic features using spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*By Sofie Mosegaard, 22-02-2024*\n",
    "\n",
    "This assignment concerns using spaCy to extract linguistic information from a corpus of texts.\n",
    "This assignment is designed to test that you can:\n",
    "\n",
    "1. Work with multiple input data arranged hierarchically in folders;\n",
    "2. Use spaCy to extract linguistic information from text data;\n",
    "3. Save those results in a clear way which can be shared or used for future analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "# python -m spacy download en_core_web_md\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the relative frequency per 10,000 words and round the decimals\n",
    "# The input is the number of POS and the total number of tokens in the given text, while the \n",
    "# output will be the he relative frquency per 10,000 words\n",
    "\n",
    "def rel_freq(count, len_doc): \n",
    "    return round((count/len_doc * 10000), 2)\n",
    "\n",
    "# Count total number of unique PER, LOC, and ORG entities\n",
    "# The input is a spacy doc object, while the output will be the total number of unique persons, locations (LOC),\n",
    "# and organisations (ORG) mentioned in the specified, input doc object.\n",
    "\n",
    "def no_unique_ents(doc):\n",
    "    enteties = []\n",
    "\n",
    "    for ent in doc.ents: \n",
    "        enteties.append((ent.text, ent.label_))\n",
    "\n",
    "    enteties_df = pd.DataFrame(enteties, columns=[\"enteties\", \"label\"])\n",
    "    enteties_df = enteties_df.drop_duplicates()\n",
    "    unique_counts = enteties_df.value_counts(subset = \"label\")\n",
    "    \n",
    "    unique_labels = ['PERSON', 'LOC', 'ORG']\n",
    "    unique_row = []\n",
    "\n",
    "    for label in unique_labels:\n",
    "        if label in (unique_counts.index):\n",
    "            unique_row.append(unique_counts[label])\n",
    "        else:\n",
    "            unique_row.append(0)\n",
    "\n",
    "    return unique_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting linguistic features using spaCy \n",
    "For each text in subfolders of the folder 'in', I will extract linguistic features and append it to a subfolder-specific table. In the end, a .csv file for each subfolder will be created and saved in the folder 'out'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, specify the filepath to the folder with all the data\n",
    "filepath = os.path.join(\n",
    "                        \"..\",\n",
    "                        \"in\",\n",
    "                        \"USEcorpus\"\n",
    "                        )\n",
    "\n",
    "# Loop over each of the 14 subfolders (a1, a2, a3...)\n",
    "for subfolder in sorted(os.listdir(filepath)): # sorted = loops through the subfolders in the original, sorted order\n",
    "    subfolder_path = os.path.join(filepath, subfolder)\n",
    "\n",
    "    if os.path.isdir(subfolder_path): # Check if the specified directory exists or nor\n",
    "\n",
    "        # Create a pandas dataframe for each subfolder with specified column names\n",
    "        out_df = pd.DataFrame(columns=(\"Filename\",\n",
    "                                        \"RelFreq NOUN\",\n",
    "                                        \"RelFreq VERB\",\n",
    "                                        \"RelFreq ADJ\",\n",
    "                                        \"RelFreq ADV\",\n",
    "                                        \"No. Unique PER\",\n",
    "                                        \"No. Unique LOC\",\n",
    "                                        \"No. Unique ORG\"))\n",
    "\n",
    "        # Loop over each text file in the subfolder\n",
    "        for file in glob.glob(os.path.join(subfolder_path, \"*.txt\")):\n",
    "            if os.path.isfile(file): # Function checks whether there excists files on the specified path\n",
    "                \n",
    "                with open(file, \"r\", encoding = \"latin-1\") as f:\n",
    "                    text = f.read()\n",
    "\n",
    "                    text = re.sub(r\"<*?>\", \"\", text) # Remove metadata between <> and replace it with \"\" (= nothing hehe)\n",
    "\n",
    "                    doc = nlp(text) # Create spacy doc\n",
    "\n",
    "                    # Count number of each POS\n",
    "                    nouns_count, verbs_count, adverb_count, adjective_count = 0, 0, 0, 0\n",
    "\n",
    "                    for token in doc:\n",
    "                        if token.pos_ == \"NOUN\":\n",
    "                            nouns_count += 1\n",
    "                        elif token.pos_ == \"VERB\":\n",
    "                            verbs_count += 1\n",
    "                        elif token.pos_ == \"ADV\":\n",
    "                            adverb_count += 1\n",
    "                        elif token.pos_ == \"ADJ\":\n",
    "                            adjective_count += 1\n",
    "            \n",
    "                    nouns_relative_freq = rel_freq(nouns_count, len(doc))\n",
    "                    verbs_relative_freq = rel_freq(verbs_count, len(doc))\n",
    "                    adjective_relative_freq = rel_freq(adjective_count, len(doc))\n",
    "                    adverb_relative_freq = rel_freq(adverb_count, len(doc))\n",
    "                    \n",
    "                    # Count total number of unique PER, LOC, and ORG entities\n",
    "                    No_unique_per, No_unique_loc, No_unique_org = no_unique_ents(doc)\n",
    "\n",
    "                    # Append the name of the text to the filenames folder \n",
    "                    text_name = file.split(\"/\")[-1]\n",
    "\n",
    "                    # Append the extracted linguistic features for each text to a row in the out_df\n",
    "                    text_row = [text_name, nouns_relative_freq,\n",
    "                                verbs_relative_freq, adjective_relative_freq,\n",
    "                                adverb_relative_freq, No_unique_per,\n",
    "                                No_unique_loc, No_unique_org]\n",
    "\n",
    "                    out_df.loc[len(out_df)] = text_row\n",
    "            \n",
    "            # Specify path to the output folcder and name of the specific .csv file\n",
    "            csv_outpath = os.path.join(\"..\", \"out\", f\"{subfolder}_data.csv\")\n",
    "\n",
    "        out_df.to_csv(csv_outpath)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test - import one .csv file to check how the table looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Filename</th>\n",
       "      <th>RelFreq NOUN</th>\n",
       "      <th>RelFreq VERB</th>\n",
       "      <th>RelFreq ADJ</th>\n",
       "      <th>RelFreq ADV</th>\n",
       "      <th>No. Unique PER</th>\n",
       "      <th>No. Unique LOC</th>\n",
       "      <th>No. Unique ORG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1112.a1.txt</td>\n",
       "      <td>1273.96</td>\n",
       "      <td>1465.61</td>\n",
       "      <td>631.34</td>\n",
       "      <td>823.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0107.a1.txt</td>\n",
       "      <td>1204.99</td>\n",
       "      <td>1440.44</td>\n",
       "      <td>886.43</td>\n",
       "      <td>609.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1071.a1.txt</td>\n",
       "      <td>1396.71</td>\n",
       "      <td>1302.82</td>\n",
       "      <td>622.07</td>\n",
       "      <td>481.22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0191.a1.txt</td>\n",
       "      <td>1251.49</td>\n",
       "      <td>1358.76</td>\n",
       "      <td>750.89</td>\n",
       "      <td>679.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3064.a1.txt</td>\n",
       "      <td>1538.46</td>\n",
       "      <td>1372.14</td>\n",
       "      <td>665.28</td>\n",
       "      <td>665.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>298</td>\n",
       "      <td>0149.a1.txt</td>\n",
       "      <td>1239.11</td>\n",
       "      <td>1239.11</td>\n",
       "      <td>735.72</td>\n",
       "      <td>735.72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>299</td>\n",
       "      <td>0100.a1.txt</td>\n",
       "      <td>1524.48</td>\n",
       "      <td>1216.78</td>\n",
       "      <td>797.20</td>\n",
       "      <td>531.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>300</td>\n",
       "      <td>3045.a1.txt</td>\n",
       "      <td>1144.58</td>\n",
       "      <td>1385.54</td>\n",
       "      <td>622.49</td>\n",
       "      <td>401.61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>301</td>\n",
       "      <td>0128.a1.txt</td>\n",
       "      <td>1355.93</td>\n",
       "      <td>1210.65</td>\n",
       "      <td>641.65</td>\n",
       "      <td>726.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>302</td>\n",
       "      <td>1062.a1.txt</td>\n",
       "      <td>1302.38</td>\n",
       "      <td>1200.45</td>\n",
       "      <td>566.25</td>\n",
       "      <td>554.93</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0     Filename  RelFreq NOUN  RelFreq VERB  RelFreq ADJ  \\\n",
       "0             0  1112.a1.txt       1273.96       1465.61       631.34   \n",
       "1             1  0107.a1.txt       1204.99       1440.44       886.43   \n",
       "2             2  1071.a1.txt       1396.71       1302.82       622.07   \n",
       "3             3  0191.a1.txt       1251.49       1358.76       750.89   \n",
       "4             4  3064.a1.txt       1538.46       1372.14       665.28   \n",
       "..          ...          ...           ...           ...          ...   \n",
       "298         298  0149.a1.txt       1239.11       1239.11       735.72   \n",
       "299         299  0100.a1.txt       1524.48       1216.78       797.20   \n",
       "300         300  3045.a1.txt       1144.58       1385.54       622.49   \n",
       "301         301  0128.a1.txt       1355.93       1210.65       641.65   \n",
       "302         302  1062.a1.txt       1302.38       1200.45       566.25   \n",
       "\n",
       "     RelFreq ADV  No. Unique PER  No. Unique LOC  No. Unique ORG  \n",
       "0         823.00               0               0               0  \n",
       "1         609.42               0               0               0  \n",
       "2         481.22               3               0               4  \n",
       "3         679.38               0               0               2  \n",
       "4         665.28               0               0               0  \n",
       "..           ...             ...             ...             ...  \n",
       "298       735.72               1               0               0  \n",
       "299       531.47               0               0               0  \n",
       "300       401.61               0               1               0  \n",
       "301       726.39               0               0               0  \n",
       "302       554.93               8               0               2  \n",
       "\n",
       "[303 rows x 9 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_tester = pd.read_csv(\"../out/a1_data.csv\")\n",
    "table_tester"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
