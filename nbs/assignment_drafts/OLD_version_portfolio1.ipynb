{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio 1 - Extracting linguistic features using spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*By Sofie Mosegaard, 22-02-2024*\n",
    "\n",
    "(OBS: I have made an error in relation to calculating the unique POS, LOC, and ORG features. In the code below, I just count the total number and not the total unique number)\n",
    "\n",
    "This assignment concerns using spaCy to extract linguistic information from a corpus of texts.\n",
    "This assignment is designed to test that you can:\n",
    "\n",
    "1. Work with multiple input data arranged hierarchically in folders;\n",
    "2. Use spaCy to extract linguistic information from text data;\n",
    "3. Save those results in a clear way which can be shared or used for future analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packacges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# python -m spacy download en_core_web_md\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting linguistic features using spaCy \n",
    "For each text in subfolders of the folder 'in', I will extract linguistic features and append it to a subfolder-specific table. In the end, a .csv file for each subfolder will be created and saved in the folder 'out'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, specify the filepath to the folder with all the data\n",
    "filepath = os.path.join(\n",
    "                        \"..\",\n",
    "                        \"in\",\n",
    "                        \"USEcorpus\"\n",
    "                        )\n",
    "\n",
    "# Loop over each of the 14 subfolders (a1, a2, a3...)\n",
    "for subfolder in sorted(os.listdir(filepath)): # sorted = loops through the subfolders in the original, sorted order\n",
    "    subfolder_path = os.path.join(filepath, subfolder)\n",
    "\n",
    "    if os.path.isdir(subfolder_path): # Check if the specified directory exists or nor\n",
    "\n",
    "        # Initialize empty lists to store data  \n",
    "        filenames = [] # Original name of the text files in the subfolders\n",
    "        nouns_freq = []\n",
    "        verbs_freq = []\n",
    "        adverbs_freq = []\n",
    "        adjectives_freq = []\n",
    "        no_unique_per = []\n",
    "        no_unique_loc = []\n",
    "        no_unique_org = []\n",
    "        enteties = []\n",
    "\n",
    "    # Loop over each text file in the subfolder\n",
    "        for file in glob.glob(os.path.join(subfolder_path, \"*.txt\")):\n",
    "            if os.path.isfile(file): # Function checks whether there excists files on the specified path\n",
    "                with open(file, \"r\", encoding = \"latin-1\") as f:\n",
    "                    text = f.read()\n",
    "\n",
    "                    text = re.sub(r\"<*?>\", \"\", text) # Remove metadata between <> and replace it with \"\" (= nothing hehe)\n",
    "\n",
    "                    doc = nlp(text) # Create spacy doc\n",
    "\n",
    "                    ### Count number of each POS ###\n",
    "\n",
    "                    # Count number of nouns\n",
    "                    nouns_count, verbs_count, adverb_count, adjective_count = 0, 0, 0, 0\n",
    "\n",
    "                    for token in doc:\n",
    "                        if token.pos_ == \"NOUN\":\n",
    "                            nouns_count += 1\n",
    "                        elif token.pos_ == \"VERB\":\n",
    "                            verbs_count += 1\n",
    "                        elif token.pos_ == \"ADV\":\n",
    "                            adverb_count += 1\n",
    "                        elif token.pos_ == \"ADJ\":\n",
    "                            adjective_count += 1\n",
    "                \n",
    "                    # Calculate their relative frequency per 10,000 words and round the decimals\n",
    "                    nouns_relative_freq = round((nouns_count/len(doc) * 10000), 2)\n",
    "                    verbs_relative_freq = round((verbs_count/len(doc) * 10000), 2)\n",
    "                    adverb_relative_freq = round((adverb_count/len(doc) * 10000), 2)\n",
    "                    adjective_relative_freq = round((adjective_count/len(doc) * 10000), 2)\n",
    "\n",
    "                    ### Count total number of unique PER, LOC, and ORG entities ###\n",
    "\n",
    "                    unique_per_count = 0\n",
    "                    unique_loc_count = 0\n",
    "                    unique_org_count = 0\n",
    "\n",
    "                    # Iterate over each entity in the spacy doc\n",
    "                    for ent in doc.ents:\n",
    "                        # Check the entity label --> if it is unique, then increment the corresponding count\n",
    "                        if ent.label_ == \"PERSON\":\n",
    "                            unique_per_count += 1\n",
    "                        elif ent.label_ == \"LOC\":\n",
    "                            unique_loc_count += 1\n",
    "                        elif ent.label_ == \"ORG\":\n",
    "                            unique_org_count += 1\n",
    "\n",
    "\n",
    "                    # Append the relative frequency of POS and counts of unique entities to the lists\n",
    "                    filenames.append(os.path.basename(file))\n",
    "                    nouns_freq.append(nouns_relative_freq)\n",
    "                    verbs_freq.append(verbs_relative_freq)\n",
    "                    adverbs_freq.append(adverb_relative_freq)\n",
    "                    adjectives_freq.append(adjective_relative_freq)\n",
    "                    #no_unique_per.append(unique_per_count)\n",
    "                    #no_unique_loc.append(unique_loc_count)\n",
    "                    #no_unique_org.append(unique_org_count)\n",
    "    \n",
    "\n",
    "    # Create a pandas dataframe for each subfolder\n",
    "    df = pd.DataFrame({\n",
    "        \"Filename\": filenames, \n",
    "        \"Nouns_Relative_Freq\": nouns_freq,\n",
    "        \"Verbs_Relative_Freq\": verbs_freq,\n",
    "        \"Adverbs_Relative_Freq\": adverbs_freq,\n",
    "        \"No_unique_per\": no_unique_per,\n",
    "        \"No_unique_loc\": no_unique_loc,\n",
    "        \"No_unique_org\": no_unique_org\n",
    "    })\n",
    "\n",
    "    # Save the dataframe as a .csv file\n",
    "    csv_filename = f\"../out/{subfolder}_data.csv\"\n",
    "    df.to_csv(csv_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test - import one .csv file to check how the table looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_tester = pd.read_csv(\"../out/a1_data.csv\")\n",
    "table_tester"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
